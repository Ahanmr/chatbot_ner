{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratik/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "from nltk.tokenize import  word_tokenize\n",
    "import tensorflow as tf\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import word embeddings and reformat\n",
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "word_vectors = gensim.models.Word2Vec.load('nearby_embeddings2')\n",
    "wordVectors = []\n",
    "for word in word_vectors.wv.index2word:\n",
    "    wordVectors.append(word_vectors.wv[word])\n",
    "wordVectors = np.array(wordVectors)\n",
    "wordsList = word_vectors.wv.index2word\n",
    "\n",
    "max_sequence_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21682"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('/home/pratik/NER/data/large_positive.csv')\n",
    "len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16623"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.drop_duplicates(subset=['body'], inplace=True)\n",
    "len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(original_text_list):\n",
    "    l = ast.literal_eval(original_text_list)\n",
    "    l = [i.strip() for i in l]\n",
    "    return l\n",
    "raw_data['original_text'] = raw_data['original_text'].apply(lambda x: convert_to_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_y(text, original_text_list, k):\n",
    "    y = np.zeros([max_sequence_length, 2])\n",
    "    try:\n",
    "        for i in range(len(y)):\n",
    "            y[i][0] = 1\n",
    "        for original_text_words in original_text_list:\n",
    "            for original_text in word_tokenize(original_text_words):\n",
    "                words = word_tokenize(text)\n",
    "                for i in range(len(words)):\n",
    "                    if words[i].lower() == original_text.lower():\n",
    "                      #  print(words[i], original_text)\n",
    "                        y[i][1] = 1\n",
    "                        y[i][0] = 0\n",
    "    except:\n",
    "        pass\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list = np.zeros([len(raw_data), max_sequence_length, 2])\n",
    "for body, original_text_list, i in zip(raw_data['body'], raw_data['original_text'], range(len(raw_data))):\n",
    "    \n",
    "    y_list[i] = generate_y(body, original_text_list, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['No', 'I', 'ask', 'Paytm', 'debit', 'card', 'queries'],\n",
       " ['paytm debit'],\n",
       " array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(raw_data['body'].iloc[11]), raw_data['original_text'].iloc[11], y_list[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = np.load('nearby_ids2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "5        None\n",
       "6        None\n",
       "7        None\n",
       "8        None\n",
       "9        None\n",
       "10       None\n",
       "11       None\n",
       "12       None\n",
       "13       None\n",
       "14       None\n",
       "15       None\n",
       "16       None\n",
       "17       None\n",
       "18       None\n",
       "19       None\n",
       "20       None\n",
       "21       None\n",
       "22       None\n",
       "23       None\n",
       "24       None\n",
       "25       None\n",
       "26       None\n",
       "27       None\n",
       "28       None\n",
       "29       None\n",
       "30       None\n",
       "         ... \n",
       "21287    None\n",
       "21288    None\n",
       "21289    None\n",
       "21290    None\n",
       "21291    None\n",
       "21292    None\n",
       "21293    None\n",
       "21294    None\n",
       "21295    None\n",
       "21296    None\n",
       "21297    None\n",
       "21298    None\n",
       "21299    None\n",
       "21301    None\n",
       "21302    None\n",
       "21304    None\n",
       "21305    None\n",
       "21306    None\n",
       "21307    None\n",
       "21309    None\n",
       "21310    None\n",
       "21311    None\n",
       "21312    None\n",
       "21313    None\n",
       "21316    None\n",
       "21318    None\n",
       "21319    None\n",
       "21320    None\n",
       "21321    None\n",
       "21322    None\n",
       "Name: body, Length: 16623, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_vocab = []\n",
    "def get_character_set(text):\n",
    "    for char in text:\n",
    "        if not char in char_vocab:\n",
    "            char_vocab.append(char)\n",
    "\n",
    "raw_data['body'].apply(lambda x: get_character_set(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_vocab_len = len(char_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "char_one_hot = np.zeros([char_vocab_len, char_vocab_len])\n",
    "for i in range(len(char_vocab)):\n",
    "    char_one_hot[i][i] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_char_length = 16\n",
    "max_sequence_length = 20\n",
    "char_dimensions = char_vocab_len\n",
    "batch_size = 100\n",
    "raw_data_len = len(raw_data)\n",
    "ids_char = np.zeros([(raw_data_len),max_sequence_length,max_char_length ])\n",
    "ids_char = ids_char + len(char_vocab) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = 0\n",
    "for i in (range((raw_data_len))):\n",
    "    body = raw_data.iloc[i]['body']\n",
    "    words = word_tokenize(body)\n",
    "    for j in (range(len(words))):\n",
    "        word = words[j]\n",
    "        for k in range(len(word)):\n",
    "            char = word[k]\n",
    "            try:\n",
    "                ids_char[i][j][k] = char_vocab.index(char)\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16623, 20, 16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_char.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdiugfh Tensor(\"map/while/TensorArrayReadV3:0\", shape=(20, 16), dtype=float32)\n",
      "char_data Tensor(\"map/while/embedding_lookup:0\", shape=(20, 16, 158), dtype=int32)\n",
      "aya\n",
      "og (20, 2528)\n",
      "con2 (20, 8, 79, 32)\n"
     ]
    }
   ],
   "source": [
    "#weights = {'W_conv1': tf.get_variable(\"W_conv1\", shape=([5,5,1,32]), dtype=tf.float32,\n",
    "#              initializer=tf.random_normal_initializer()),\n",
    "#           'W_conv2':                tf.get_variable(\"W_conv2\", shape=([5,5,32,64]), dtype=tf.float32,\n",
    "#              initializer=tf.random_normal_initializer()),\n",
    "#           'W_fc':tf.get_variable(\"W_fc\", shape=([(int(max_char_length//4))*(int(char_dimensions//4))*64,1024]), dtype=tf.float32,\n",
    "#              initializer=tf.random_normal_initializer())\n",
    "#           }\n",
    "\n",
    "\n",
    "\n",
    "#biases = {'b_conv1':tf.get_variable(\"b_conv1\", shape=([32]), dtype=tf.float32,\n",
    "#              initializer=tf.random_normal_initializer()),\n",
    "#           'b_conv2':tf.get_variable(\"b_conv2\", shape=([64]), dtype=tf.float32,\n",
    "#              initializer=tf.random_normal_initializer()),\n",
    "#           'b_fc':tf.get_variable(\"b_fc\", shape=([1024]), dtype=tf.float32,\n",
    "#              initializer=tf.random_normal_initializer())\n",
    "#           }\n",
    "weights = {'W_conv1':tf.Variable(tf.random_normal([5,5,1,32])),\n",
    "           'W_conv2':tf.Variable(tf.random_normal([5,5,32,64])),\n",
    "           'W_fc':tf.Variable(tf.random_normal([(int(max_char_length//2))*(int(char_dimensions//2))*32,100])),\n",
    "           'out':tf.Variable(tf.random_normal([100, 10]))}\n",
    "\n",
    "biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n",
    "           'b_conv2':tf.Variable(tf.random_normal([64])),\n",
    "           'b_fc':tf.Variable(tf.random_normal([100])),\n",
    "           'out':tf.Variable(tf.random_normal([10]))}\n",
    "\n",
    "def character_level_embedding(char_input_data):\n",
    "    print('sdiugfh', char_input_data)\n",
    "    char_input_data = tf.cast(char_input_data, dtype=tf.int32)\n",
    "    char_one_hot_tensor = tf.convert_to_tensor(char_one_hot, dtype=tf.int32)\n",
    "    char_data = tf.placeholder(shape = (max_sequence_length,max_char_length), dtype=tf.int32)\n",
    "    char_data = tf.nn.embedding_lookup(char_one_hot_tensor,char_input_data)\n",
    "    print('char_data', char_data)\n",
    "    keep_rate = 1\n",
    "    print('aya')\n",
    "    n_nodes_hl1 = 100\n",
    "    #print(char_data.shape)\n",
    "#The place holder to hold the values of new x and y at different times.\n",
    "    x = tf.placeholder(dtype=tf.float32, shape=[max_sequence_length, max_char_length * char_dimensions])\n",
    "    x = tf.cast(tf.reshape(char_data, shape=[max_sequence_length, max_char_length * char_dimensions]), dtype=tf.float32)\n",
    "    #print(x)\n",
    "#y = tf.placeholder('float', [batch_size, n_classes])\n",
    "\n",
    "    def embedding_layer(data):\n",
    "        print('aya')\n",
    "        hidden_1_layer = {'weights':tf.Variable(tf.random_normal([max_char_length * char_dimensions, n_nodes_hl1])),\n",
    "                          'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "        l1 = tf.add(tf.tensordot(data,hidden_1_layer['weights'], axes=1), hidden_1_layer['biases'])\n",
    "        l1 = tf.nn.relu(l1)\n",
    "        print(l1.shape)\n",
    "        return l1\n",
    "\n",
    "    def conv2d(x, W):\n",
    "        return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "    def maxpool2d(x):\n",
    "        #                        size of window         movement of window\n",
    "        return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "\n",
    "    def convolutional_neural_network(x):\n",
    "        \n",
    "#        tf.get_variable(\"W_conv1\", shape=([5,5,1,32]), dtype=tf.int32,\n",
    "#                      initializer=tf.ones_initializer())\n",
    "#                tf.get_variable(\"W_conv2\", shape=([5,5,32,64]), dtype=tf.int32,\n",
    "#                      initializer=tf.ones_initializer())\n",
    "#        \n",
    "#                        tf.get_variable(\"W_fc\", shape=([(int(max_char_length//4))*(int(char_dimensions//4))*64,1024]), dtype=tf.int32,\n",
    "#                      initializer=tf.ones_initializer())\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        print('og', x.shape)\n",
    "        x = tf.reshape(x, shape=[max_sequence_length,max_char_length,char_dimensions, 1])\n",
    "\n",
    "        conv1 = tf.nn.relu(conv2d(x, weights['W_conv1']) + biases['b_conv1'])\n",
    "        conv2 = maxpool2d(conv1)\n",
    "\n",
    "        #conv2 = tf.nn.relu(conv2d(conv1, weights['W_conv2']) + biases['b_conv2'])\n",
    "        #conv2 = maxpool2d(conv2)\n",
    "        \n",
    "        print('con2',conv2.shape)\n",
    "        fc = tf.reshape(conv2,[max_sequence_length, (max_char_length//2) * (char_dimensions//2) * 32])\n",
    "        fc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n",
    "        fc = tf.nn.dropout(fc, keep_rate)\n",
    "        #print(fc.shape)\n",
    "        return fc\n",
    "\n",
    "    def train_neural_network(x):    \n",
    "        #embedded_x = embedding_layer(x)\n",
    "        #embedded_x = tf.reshape(x, [max_sequence_length, char_dimensions])\n",
    "        convoluted_x = convolutional_neural_network(x)\n",
    "        \n",
    "        return convoluted_x\n",
    "    \n",
    "    char_data = train_neural_network(x)\n",
    "    return char_data\n",
    "\n",
    "\n",
    "char_input_data = tf.placeholder(dtype=tf.float32,shape= [batch_size, max_sequence_length, max_char_length])\n",
    "char_embeddings = tf.map_fn(lambda x: character_level_embedding(x), char_input_data, dtype=tf.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n",
      "(100, 20, 100)\n"
     ]
    }
   ],
   "source": [
    "init_g = tf.global_variables_initializer()\n",
    "init_l = tf.local_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_g)\n",
    "    sess.run(init_l)\n",
    "    p = ids_char.astype(int)[100:200]\n",
    "    print(type(p[0][0][0]))\n",
    "    b = sess.run([char_embeddings], feed_dict={char_input_data: p})\n",
    "    print(b[0].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 2623, 14000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstmUnits = 64\n",
    "numClasses = 2\n",
    "epochs = 10\n",
    "numDimensions = 100\n",
    "batchSize = 100\n",
    "train_len = 14000\n",
    "\n",
    "X_train = ids[:train_len]\n",
    "y_train = y_list[:train_len]\n",
    "X_test = ids[train_len:]\n",
    "y_test = y_list[train_len:]\n",
    "ids_char_train = ids_char[:train_len]\n",
    "ids_char_test = ids_char[train_len:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test, ids_char_train, ids_char_test = train_test_split(ids,y_list,ids_char, test_size=.2)\n",
    "\n",
    "len(X_train), len(y_test), len(ids_char_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTrainBatch(j):\n",
    "    i = j*batchSize\n",
    "    arr = X_train[i:i+batchSize]\n",
    "    labels = y_train[i:i+batchSize]\n",
    "    arr_char = ids_char_train[i:i+batchSize]\n",
    "    #print(labels[0])\n",
    "    return arr, labels, arr_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTestBatch(j):\n",
    "    i = j*batchSize\n",
    "    arr = X_test[i:i+batchSize]\n",
    "    labels =   y_test[i:i+batchSize]\n",
    "    arr_char = ids_char_test[i:i+batchSize]\n",
    "    return arr, labels, arr_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = tf.placeholder(tf.float32, [batchSize, max_sequence_length, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, max_sequence_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordVectors = tf.convert_to_tensor(wordVectors, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20, 100)\n",
      "(100, 20, 100)\n"
     ]
    }
   ],
   "source": [
    "data = tf.placeholder(shape = (batchSize,max_sequence_length,numDimensions), dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)\n",
    "print(data.shape)\n",
    "print(char_embeddings.shape)\n",
    "data2 = tf.placeholder(shape = (batchSize,max_sequence_length,numDimensions+char_dimensions), dtype=tf.float32)\n",
    "data2 = tf.concat([data, char_embeddings], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fw_cell3 = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.BasicLSTMCell(lstmUnits, state_is_tuple=True) for _ in range(2)])\n",
    "bw_cell3 = tf.nn.rnn_cell.MultiRNNCell([ tf.nn.rnn_cell.BasicLSTMCell(lstmUnits, state_is_tuple=True) for _ in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs,value2 = tf.nn.bidirectional_dynamic_rnn(fw_cell3, bw_cell3,data2,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(outputs)\n",
    "\n",
    "outputs = tf.concat(outputs, 2)\n",
    "#print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([lstmUnits*2,numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[batchSize,max_sequence_length,numClasses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20) (100, 20) (22.0, 22.0) (135.0, 135.0) (22.0, 22.0) (1821.0, 1821.0)\n"
     ]
    }
   ],
   "source": [
    "prediction = (tf.tensordot(outputs, weight, axes=((2,),(0,))) + bias)\n",
    "prediction_arg = tf.argmax(prediction,axis=2)\n",
    "label_arg = tf.argmax(labels,axis=2)\n",
    "#false_positives\n",
    "false_positives = tf.metrics.false_positives(predictions=prediction_arg, labels=label_arg)\n",
    "false_negatives = tf.metrics.false_negatives(predictions=prediction_arg, labels=label_arg)\n",
    "true_positives = tf.metrics.true_positives(predictions=prediction_arg, labels=label_arg)\n",
    "true_negatives = tf.metrics.true_negatives(predictions=prediction_arg, labels=label_arg)\n",
    "prec = tf.metrics.precision(predictions=prediction_arg, labels=label_arg)\n",
    "rec = tf.metrics.recall(predictions=prediction_arg, labels=label_arg)\n",
    "#false_positives = 1\n",
    "init_g = tf.global_variables_initializer()\n",
    "init_l = tf.local_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    #tf.initialize_all_variables().run()\n",
    "    sess.run(init_g)\n",
    "    sess.run(init_l)\n",
    "    nextBatch, nextBatchLabels, nextChars = getTrainBatch(2)\n",
    "        #print(j/2)\n",
    "    pred, pa, la, fp, fn, tp, tn = sess.run([prediction, prediction_arg, label_arg, false_positives, false_negatives, true_positives, true_negatives], {input_data: nextBatch, labels: nextBatchLabels, char_input_data: nextChars})\n",
    "    print(pa.shape, la.shape, fp, fn, tp, tn)\n",
    "    #a = pred[0]\n",
    "    #b = nextBatchLabels\n",
    "   # print(a.shape,b.shape)\n",
    "    #print(a.shape)\n",
    "    #print(np.argmax(a, axis=2)[0])\n",
    "    #print(np.argmax(b, axis=2)[0])\n",
    "    #print(np.logical_and(np.argmax(a, axis=2)[0], np.argmax(b, axis=2)[0] ))\n",
    "    #print((np.equal(np.argmax(a, axis=2), np.argmax(b, axis=2)))[0])\n",
    "    #print(np.mean(np.equal(np.argmax(a, axis=2), np.argmax(b, axis=2)), axis=1))\n",
    "    #print(np.mean(np.equal(np.argmax(a, axis=2), np.argmax(b, axis=2)), axis=0))\n",
    "    #print(np.mean(np.equal(np.argmax(a, axis=2), np.argmax(b, axis=2))))\n",
    "correctPred = tf.equal(tf.argmax(prediction,axis=2), tf.argmax(labels,axis=2))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-31-297707c63317>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with tf.Session() as sess:\n",
    "#    sess.run(tf.global_variables_initializer())#\n",
    "\n",
    "#    o,w,b,p = sess.run([outputs,weight,bias,prediction],feed_dict={input_data: X_train[:100], labels: y_train[:100]})\n",
    "#    print(np.array(o).shape,np.array(w).shape,np.array(b).shape,np.array(p).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "0.47051436\n",
      "0.28845656\n",
      "0.26291314\n",
      "0.17598605\n",
      "0.15089364\n",
      "0.13974608\n",
      "0.1374718\n",
      "0.13329159\n",
      "0.13983075\n",
      "0.12907177\n",
      "0.1208552\n",
      "0.121448\n",
      "0.14193553\n",
      "0.13944641\n",
      "0.1402088\n",
      "0.1424089\n",
      "0.17134576\n",
      "0.12836084\n",
      "0.13334735\n",
      "0.10248407\n",
      "0.11797108\n",
      "0.10148063\n",
      "0.13616812\n",
      "0.1164169\n",
      "0.10221283\n",
      "0.12358316\n",
      "0.11421058\n",
      "0.10240166\n",
      "0.10386746\n",
      "0.104171716\n",
      "0.09735054\n",
      "0.10067481\n",
      "0.117694445\n",
      "0.114283726\n",
      "0.10272866\n",
      "0.09734253\n",
      "0.090941206\n",
      "0.09508572\n",
      "0.0835343\n",
      "0.08833467\n",
      "0.09679099\n",
      "0.06772909\n",
      "0.08993776\n",
      "0.09574391\n",
      "0.09765942\n",
      "0.0921088\n",
      "0.081579305\n",
      "0.077173874\n",
      "0.08306076\n",
      "0.07561971\n",
      "0.13100271\n",
      "saved to models/pretrained_lstm.ckpt-0\n",
      "0.11637102\n",
      "0.13557567\n",
      "0.092320554\n",
      "0.10761876\n",
      "0.102731235\n",
      "0.10587241\n",
      "0.078667805\n",
      "0.10571417\n",
      "0.08514621\n",
      "0.09793065\n",
      "0.090119995\n",
      "0.09726402\n",
      "0.109728284\n",
      "0.073207624\n",
      "0.08126083\n",
      "0.0846416\n",
      "0.07897229\n",
      "0.08501677\n",
      "0.11323842\n",
      "0.08285716\n",
      "0.09614566\n",
      "0.09297543\n",
      "0.099504545\n",
      "0.06456216\n",
      "0.06882134\n",
      "0.08193846\n",
      "0.08409824\n",
      "0.0706199\n",
      "0.06448699\n",
      "0.07311659\n",
      "0.07349131\n",
      "0.07465343\n",
      "0.07027827\n",
      "0.066766694\n",
      "0.066139214\n",
      "0.07074771\n",
      "0.119419366\n",
      "0.09659157\n",
      "0.098103285\n",
      "0.095370375\n",
      "0.073947005\n",
      "0.071728416\n",
      "0.07051083\n",
      "0.06949581\n",
      "0.08181419\n",
      "0.086724475\n",
      "0.064104564\n",
      "0.057181403\n",
      "0.08092761\n",
      "0.07353796\n",
      "saved to models/pretrained_lstm.ckpt-0\n",
      "0.07527976\n",
      "0.07231261\n",
      "0.07550452\n",
      "0.08395668\n",
      "0.10226427\n",
      "0.08207811\n",
      "0.09430214\n",
      "0.06440271\n",
      "0.06304998\n",
      "0.060478356\n",
      "0.06363759\n",
      "0.06535001\n",
      "0.056358267\n",
      "0.072565265\n",
      "0.060830764\n",
      "0.05844574\n",
      "0.07352328\n",
      "0.069895945\n",
      "0.08312573\n",
      "0.106024615\n",
      "0.095908694\n",
      "0.07530247\n",
      "0.087473296\n",
      "0.060659196\n",
      "0.08062982\n",
      "0.05786969\n",
      "0.05490042\n",
      "0.064730294\n",
      "0.07256875\n",
      "0.10482956\n",
      "0.09709119\n",
      "0.10066135\n",
      "0.0974958\n",
      "0.06483244\n",
      "0.07603228\n",
      "0.061546683\n",
      "0.06595155\n",
      "0.058087632\n",
      "0.06490797\n",
      "13.675801366567612\n",
      "epoch:  1\n",
      "0.079408474\n",
      "0.07906622\n",
      "0.055338457\n",
      "0.050571\n",
      "0.057528246\n",
      "0.07181544\n",
      "0.052489754\n",
      "0.059853654\n",
      "0.07249686\n",
      "0.05015106\n",
      "0.050172456\n",
      "0.06847412\n",
      "0.06363925\n",
      "0.087482475\n",
      "0.071532205\n",
      "0.10661081\n",
      "0.0885195\n",
      "0.078136936\n",
      "0.07377952\n",
      "0.08316652\n",
      "0.06685725\n",
      "0.059299044\n",
      "0.07092625\n",
      "0.06529438\n",
      "0.057710953\n",
      "0.061917804\n",
      "0.07439739\n",
      "0.055415757\n",
      "0.06052273\n",
      "0.06255149\n",
      "0.064079076\n",
      "0.06496203\n",
      "0.09285721\n",
      "0.08632173\n",
      "0.08308093\n",
      "0.07005897\n",
      "0.058118317\n",
      "0.068693355\n",
      "0.06263172\n",
      "0.057687182\n",
      "0.07137635\n",
      "0.05060486\n",
      "0.06492196\n",
      "0.06150216\n",
      "0.068431586\n",
      "0.072883196\n",
      "0.05522955\n",
      "0.05940572\n",
      "0.062825195\n",
      "0.052019846\n",
      "0.08635645\n",
      "saved to models/pretrained_lstm.ckpt-1\n",
      "0.080984585\n",
      "0.08871707\n",
      "0.07044513\n",
      "0.074185655\n",
      "0.06591373\n",
      "0.0749092\n",
      "0.060148254\n",
      "0.08165205\n",
      "0.06358711\n",
      "0.07142575\n",
      "0.0689335\n",
      "0.07787602\n",
      "0.085482635\n",
      "0.059499763\n",
      "0.060847707\n",
      "0.07422475\n",
      "0.05956248\n",
      "0.07726582\n",
      "0.096595556\n",
      "0.06606997\n",
      "0.08453988\n",
      "0.07149679\n",
      "0.075350724\n",
      "0.051582366\n",
      "0.058178995\n",
      "0.069235995\n",
      "0.07168444\n",
      "0.057539154\n",
      "0.055942997\n",
      "0.06386654\n",
      "0.07211893\n",
      "0.061215598\n",
      "0.06455943\n",
      "0.062453143\n",
      "0.056113217\n",
      "0.066768326\n",
      "0.09899817\n",
      "0.093043216\n",
      "0.08756523\n",
      "0.09031854\n",
      "0.071759015\n",
      "0.06444137\n",
      "0.06725213\n",
      "0.06674636\n",
      "0.07595113\n",
      "0.08166098\n",
      "0.062407147\n",
      "0.0570881\n",
      "0.07837524\n",
      "0.07018338\n",
      "saved to models/pretrained_lstm.ckpt-1\n",
      "0.072946884\n",
      "0.07219173\n",
      "0.07073865\n",
      "0.07547116\n",
      "0.09867015\n",
      "0.08728376\n",
      "0.08924423\n",
      "0.06450873\n",
      "0.06123826\n",
      "0.060114734\n",
      "0.06328512\n",
      "0.060100522\n",
      "0.055628806\n",
      "0.07887693\n",
      "0.06310882\n",
      "0.06032194\n",
      "0.06585147\n",
      "0.14766146\n",
      "0.089861386\n",
      "0.13230442\n",
      "0.09330786\n",
      "0.07903904\n",
      "0.097128525\n",
      "0.05897263\n",
      "0.07145489\n",
      "0.0509907\n",
      "0.0549282\n",
      "0.06117064\n",
      "0.07165007\n",
      "0.101262055\n",
      "0.09199693\n",
      "0.09709442\n",
      "0.09444888\n",
      "0.061691195\n",
      "0.06926779\n",
      "0.065472476\n",
      "0.064738214\n",
      "0.057271462\n",
      "0.067281656\n",
      "9.99451345950365\n",
      "epoch:  2\n",
      "0.07723422\n",
      "0.0698029\n",
      "0.050344072\n",
      "0.05003377\n",
      "0.05221849\n",
      "0.07412615\n",
      "0.049910612\n",
      "0.058957484\n",
      "0.065234095\n",
      "0.04864286\n",
      "0.04773683\n",
      "0.06434407\n",
      "0.06704132\n",
      "0.083329774\n",
      "0.07417773\n",
      "0.09361292\n",
      "0.079136886\n",
      "0.06351679\n",
      "0.06976751\n",
      "0.058583308\n",
      "0.06142691\n",
      "0.0549374\n",
      "0.06496464\n",
      "0.057110984\n",
      "0.053714078\n",
      "0.054971855\n",
      "0.06923006\n",
      "0.051060457\n",
      "0.05165647\n",
      "0.056353323\n",
      "0.05900927\n",
      "0.058819067\n",
      "0.08970026\n",
      "0.08066593\n",
      "0.07373666\n",
      "0.060948364\n",
      "0.057243172\n",
      "0.06469106\n",
      "0.057997424\n",
      "0.05370431\n",
      "0.059069816\n",
      "0.04502509\n",
      "0.061937217\n",
      "0.05559398\n",
      "0.07217505\n",
      "0.06732352\n",
      "0.0574306\n",
      "0.058545742\n",
      "0.056376655\n",
      "0.049524326\n",
      "0.08598773\n",
      "saved to models/pretrained_lstm.ckpt-2\n",
      "0.08037302\n",
      "0.08156389\n",
      "0.06722725\n",
      "0.0719351\n",
      "0.0681302\n",
      "0.0752825\n",
      "0.061834175\n",
      "0.08525636\n",
      "0.06396035\n",
      "0.07047593\n",
      "0.06745908\n",
      "0.07050133\n",
      "0.07858492\n",
      "0.055495955\n",
      "0.056278527\n",
      "0.071654856\n",
      "0.057616334\n",
      "0.07044591\n",
      "0.09287009\n",
      "0.0629074\n",
      "0.080625944\n",
      "0.0713811\n",
      "0.07105006\n",
      "0.04872161\n",
      "0.055693794\n",
      "0.06265181\n",
      "0.07155487\n",
      "0.052017502\n",
      "0.051691495\n",
      "0.0597844\n",
      "0.06700287\n",
      "0.062393527\n",
      "0.060169507\n",
      "0.05354351\n",
      "0.05445471\n",
      "0.058015116\n",
      "0.09522762\n",
      "0.0836095\n",
      "0.08932215\n",
      "0.07566701\n",
      "0.06609428\n",
      "0.05983368\n",
      "0.055973135\n",
      "0.053279076\n",
      "0.0684699\n",
      "0.07167005\n",
      "0.05607281\n",
      "0.052293483\n",
      "0.06096799\n",
      "0.061051544\n",
      "saved to models/pretrained_lstm.ckpt-2\n",
      "0.06622165\n",
      "0.06314303\n",
      "0.06861365\n",
      "0.06605408\n",
      "0.09045661\n",
      "0.07220333\n",
      "0.07929095\n",
      "0.05627694\n",
      "0.05138376\n",
      "0.05761458\n",
      "0.05941425\n",
      "0.058846276\n",
      "0.051157366\n",
      "0.061936356\n",
      "0.057657223\n",
      "0.048788905\n",
      "0.06053121\n",
      "0.06511017\n",
      "0.070385516\n",
      "0.087367736\n",
      "0.08458591\n",
      "0.06272113\n",
      "0.07326467\n",
      "0.046456557\n",
      "0.06651553\n",
      "0.05009314\n",
      "0.047278464\n",
      "0.05715264\n",
      "0.06533985\n",
      "0.093104154\n",
      "0.087220445\n",
      "0.089384586\n",
      "0.08859633\n",
      "0.056896143\n",
      "0.068553194\n",
      "0.057128895\n",
      "0.059591062\n",
      "0.04502764\n",
      "0.059641995\n",
      "9.089826352894306\n",
      "epoch:  3\n",
      "0.074573964\n",
      "0.06668671\n",
      "0.047942396\n",
      "0.043753143\n",
      "0.052505434\n",
      "0.06313099\n",
      "0.040806927\n",
      "0.052322112\n",
      "0.06327893\n",
      "0.0420001\n",
      "0.039997075\n",
      "0.059850886\n",
      "0.06162768\n",
      "0.071249664\n",
      "0.06009835\n",
      "0.104533546\n",
      "0.08211478\n",
      "0.064344876\n",
      "0.071924806\n",
      "0.053556196\n",
      "0.05665811\n",
      "0.053462982\n",
      "0.068728685\n",
      "0.057693433\n",
      "0.05219516\n",
      "0.05679124\n",
      "0.0639406\n",
      "0.049124185\n",
      "0.048162054\n",
      "0.056394204\n",
      "0.06058931\n",
      "0.05581541\n",
      "0.08711265\n",
      "0.07619852\n",
      "0.067140095\n",
      "0.056572575\n",
      "0.054114457\n",
      "0.06688433\n",
      "0.050614987\n",
      "0.050808337\n",
      "0.06012689\n",
      "0.048517264\n",
      "0.059592143\n",
      "0.054252412\n",
      "0.07126845\n",
      "0.06336975\n",
      "0.05403501\n",
      "0.05051613\n",
      "0.058450837\n",
      "0.050539076\n",
      "0.07979575\n",
      "saved to models/pretrained_lstm.ckpt-3\n",
      "0.072162524\n",
      "0.07844354\n",
      "0.06083921\n",
      "0.06484477\n",
      "0.06291111\n",
      "0.07306069\n",
      "0.05721369\n",
      "0.08154718\n",
      "0.0636414\n",
      "0.06829002\n",
      "0.06673459\n",
      "0.07350658\n",
      "0.082118385\n",
      "0.054616578\n",
      "0.04987882\n",
      "0.0705589\n",
      "0.050395027\n",
      "0.06800114\n",
      "0.09076678\n",
      "0.058497682\n",
      "0.07788681\n",
      "0.0645367\n",
      "0.0694907\n",
      "0.04745568\n",
      "0.055914123\n",
      "0.06324453\n",
      "0.06467379\n",
      "0.0475816\n",
      "0.049867395\n",
      "0.056383874\n",
      "0.06350437\n",
      "0.059684135\n",
      "0.055838197\n",
      "0.05196245\n",
      "0.04986169\n",
      "0.05423703\n",
      "0.08306273\n",
      "0.07966614\n",
      "0.08428227\n",
      "0.071238644\n",
      "0.057844095\n",
      "0.053163595\n",
      "0.054527707\n",
      "0.05312825\n",
      "0.06742751\n",
      "0.06653282\n",
      "0.05175704\n",
      "0.04685787\n",
      "0.057960708\n",
      "0.06288634\n",
      "saved to models/pretrained_lstm.ckpt-3\n",
      "0.06153976\n",
      "0.05636741\n",
      "0.06701777\n",
      "0.06446605\n",
      "0.0865315\n",
      "0.06433583\n",
      "0.07393605\n",
      "0.060216025\n",
      "0.050801247\n",
      "0.055307597\n",
      "0.05891016\n",
      "0.058737397\n",
      "0.04790835\n",
      "0.06867632\n",
      "0.05866155\n",
      "0.05258778\n",
      "0.06523728\n",
      "0.058379892\n",
      "0.06821281\n",
      "0.08550095\n",
      "0.08330008\n",
      "0.064144045\n",
      "0.073140234\n",
      "0.046337057\n",
      "0.06620659\n",
      "0.048733134\n",
      "0.044611614\n",
      "0.05191712\n",
      "0.062859215\n",
      "0.09205447\n",
      "0.07812272\n",
      "0.08932138\n",
      "0.08682515\n",
      "0.062318847\n",
      "0.07200801\n",
      "0.057867907\n",
      "0.062394887\n",
      "0.047259137\n",
      "0.05607484\n",
      "8.735079176723957\n",
      "epoch:  4\n",
      "0.06693277\n",
      "0.067513324\n",
      "0.048189867\n",
      "0.0455944\n",
      "0.05280085\n",
      "0.0611988\n",
      "0.04297788\n",
      "0.049081583\n",
      "0.059638202\n",
      "0.040883712\n",
      "0.039163567\n",
      "0.057851434\n",
      "0.06276036\n",
      "0.06445224\n",
      "0.055662353\n",
      "0.08292257\n",
      "0.07664766\n",
      "0.06029058\n",
      "0.06659252\n",
      "0.050036732\n",
      "0.056832824\n",
      "0.053112336\n",
      "0.06447069\n",
      "0.053271122\n",
      "0.052987806\n",
      "0.052869942\n",
      "0.061344292\n",
      "0.052738845\n",
      "0.054319177\n",
      "0.054853167\n",
      "0.0640204\n",
      "0.05982218\n",
      "0.09145451\n",
      "0.090817206\n",
      "0.07652665\n",
      "0.065098815\n",
      "0.057597626\n",
      "0.06977735\n",
      "0.051116854\n",
      "0.05296951\n",
      "0.057207737\n",
      "0.048250172\n",
      "0.09284065\n",
      "0.066704005\n",
      "0.075943604\n",
      "0.07406013\n",
      "0.061073843\n",
      "0.055921875\n",
      "0.057843506\n",
      "0.055618677\n",
      "0.076916374\n",
      "saved to models/pretrained_lstm.ckpt-4\n",
      "0.075370766\n",
      "0.07850456\n",
      "0.05994269\n",
      "0.064934246\n",
      "0.06537524\n",
      "0.07060642\n",
      "0.06137523\n",
      "0.0828979\n",
      "0.06054674\n",
      "0.06306948\n",
      "0.06012692\n",
      "0.073206276\n",
      "0.07928943\n",
      "0.05404439\n",
      "0.055405866\n",
      "0.07064116\n",
      "0.053880125\n",
      "0.066000335\n",
      "0.08989541\n",
      "0.06358116\n",
      "0.07237369\n",
      "0.062164534\n",
      "0.07452284\n",
      "0.047244467\n",
      "0.058544055\n",
      "0.058103535\n",
      "0.072859496\n",
      "0.047836367\n",
      "0.050124854\n",
      "0.06331169\n",
      "0.06771658\n",
      "0.061729856\n",
      "0.0626491\n",
      "0.05529489\n",
      "0.05068855\n",
      "0.052161273\n",
      "0.08222701\n",
      "0.0786956\n",
      "0.08166705\n",
      "0.07221751\n",
      "0.0595337\n",
      "0.054420408\n",
      "0.052895952\n",
      "0.05038734\n",
      "0.062482208\n",
      "0.06358268\n",
      "0.048892364\n",
      "0.045934714\n",
      "0.056932397\n",
      "0.060188577\n",
      "saved to models/pretrained_lstm.ckpt-4\n",
      "0.060521964\n",
      "0.05487618\n",
      "0.06372709\n",
      "0.06656642\n",
      "0.0871536\n",
      "0.06457133\n",
      "0.079075634\n",
      "0.058053453\n",
      "0.050659142\n",
      "0.051730912\n",
      "0.052695863\n",
      "0.059115216\n",
      "0.04473271\n",
      "0.061002664\n",
      "0.054222275\n",
      "0.048540697\n",
      "0.06168504\n",
      "0.056837626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06375275\n",
      "0.078715704\n",
      "0.078384906\n",
      "0.06153666\n",
      "0.0710481\n",
      "0.040007986\n",
      "0.05973678\n",
      "0.040533215\n",
      "0.038818672\n",
      "0.049738247\n",
      "0.05860888\n",
      "0.08617588\n",
      "0.07868852\n",
      "0.08379135\n",
      "0.082726285\n",
      "0.050488226\n",
      "0.068441115\n",
      "0.05657608\n",
      "0.053296585\n",
      "0.040728055\n",
      "0.056565344\n",
      "8.659778069704771\n",
      "epoch:  5\n",
      "0.06295545\n",
      "0.06425438\n",
      "0.04598256\n",
      "0.043067634\n",
      "0.053641226\n",
      "0.060260516\n",
      "0.042013336\n",
      "0.04646174\n",
      "0.062252067\n",
      "0.041488376\n",
      "0.036517646\n",
      "0.06181047\n",
      "0.05228867\n",
      "0.06356342\n",
      "0.05596576\n",
      "0.081834495\n",
      "0.074313365\n",
      "0.054896597\n",
      "0.061436556\n",
      "0.04551567\n",
      "0.05398053\n",
      "0.047426924\n",
      "0.053197708\n",
      "0.05059548\n",
      "0.048740014\n",
      "0.04713599\n",
      "0.060294688\n",
      "0.044441026\n",
      "0.04861605\n",
      "0.051803727\n",
      "0.05443354\n",
      "0.0505364\n",
      "0.07775758\n",
      "0.07165908\n",
      "0.0725974\n",
      "0.05506374\n",
      "0.049909007\n",
      "0.06117126\n",
      "0.048470803\n",
      "0.048811104\n",
      "0.050489135\n",
      "0.044970367\n",
      "0.051950425\n",
      "0.0471977\n",
      "0.06176563\n",
      "0.057399128\n",
      "0.04652334\n",
      "0.052617952\n",
      "0.052776\n",
      "0.044446785\n",
      "0.07186432\n",
      "saved to models/pretrained_lstm.ckpt-5\n",
      "0.06609795\n",
      "0.07637083\n",
      "0.05571607\n",
      "0.061343193\n",
      "0.060729727\n",
      "0.06988373\n",
      "0.060086276\n",
      "0.07755919\n",
      "0.054794334\n",
      "0.065521136\n",
      "0.05635068\n",
      "0.0699568\n",
      "0.07054344\n",
      "0.05356045\n",
      "0.052986108\n",
      "0.06557108\n",
      "0.05028908\n",
      "0.06633194\n",
      "0.09292531\n",
      "0.059285235\n",
      "0.07121143\n",
      "0.068883345\n",
      "0.06797233\n",
      "0.04085078\n",
      "0.062678196\n",
      "0.06667777\n",
      "0.057439163\n",
      "0.043773983\n",
      "0.042716637\n",
      "0.055535965\n",
      "0.0640015\n",
      "0.05441503\n",
      "0.05827588\n",
      "0.05387329\n",
      "0.049920358\n",
      "0.05962088\n",
      "0.08474366\n",
      "0.0796571\n",
      "0.08544514\n",
      "0.103269815\n",
      "0.06961626\n",
      "0.08067473\n",
      "0.069060534\n",
      "0.058510132\n",
      "0.075462945\n",
      "0.08497235\n",
      "0.06305873\n",
      "0.05789251\n",
      "0.06755151\n",
      "0.07338452\n",
      "saved to models/pretrained_lstm.ckpt-5\n",
      "0.076895185\n",
      "0.06136957\n",
      "0.06405161\n",
      "0.071831256\n",
      "0.09231216\n",
      "0.07125824\n",
      "0.081178956\n",
      "0.06415268\n",
      "0.05634797\n",
      "0.059910756\n",
      "0.06322855\n",
      "0.066379644\n",
      "0.050369658\n",
      "0.072513506\n",
      "0.0774387\n",
      "0.063898094\n",
      "0.13768075\n",
      "0.11897603\n",
      "0.11032283\n",
      "0.17568426\n",
      "0.11536248\n",
      "0.14783478\n",
      "0.11908468\n",
      "0.08657566\n",
      "0.10124883\n",
      "0.08625102\n",
      "0.07945697\n",
      "0.073464796\n",
      "0.10666368\n",
      "0.13798621\n",
      "0.11259891\n",
      "0.13976671\n",
      "0.115787975\n",
      "0.13606472\n",
      "0.09183882\n",
      "0.099393785\n",
      "0.093646176\n",
      "0.074343495\n",
      "0.08859035\n",
      "9.687972243875265\n",
      "epoch:  6\n",
      "0.10641693\n",
      "0.10560858\n",
      "0.07692416\n",
      "0.08513471\n",
      "0.075802706\n",
      "0.10250269\n",
      "0.08129289\n",
      "0.08671977\n",
      "0.12403643\n",
      "0.068091124\n",
      "0.082566686\n",
      "0.08921695\n",
      "0.091070674\n",
      "0.106258474\n",
      "0.09720503\n",
      "0.11553933\n",
      "0.1286668\n",
      "0.085705444\n",
      "0.10004697\n",
      "0.06981602\n",
      "0.095135115\n",
      "0.08035927\n",
      "0.10639136\n",
      "0.09502565\n",
      "0.08258858\n",
      "0.08604862\n",
      "0.09211961\n",
      "0.07204846\n",
      "0.078229055\n",
      "0.08351764\n",
      "0.07705815\n",
      "0.07231042\n",
      "0.106467225\n",
      "0.09441789\n",
      "0.0827982\n",
      "0.07660234\n",
      "0.0780126\n",
      "0.09199846\n",
      "0.07105067\n",
      "0.065296054\n",
      "0.07358058\n",
      "0.07600439\n",
      "0.071320266\n",
      "0.080067426\n",
      "0.090439476\n",
      "0.082740046\n",
      "0.07559325\n",
      "0.07530699\n",
      "0.07047876\n",
      "0.059665725\n",
      "0.10729218\n",
      "saved to models/pretrained_lstm.ckpt-6\n",
      "0.0981891\n",
      "0.09846654\n",
      "0.07748294\n",
      "0.08510013\n",
      "0.0807423\n",
      "0.08083881\n",
      "0.06782468\n",
      "0.09323114\n",
      "0.07994819\n",
      "0.08191067\n",
      "0.077857025\n",
      "0.09180682\n",
      "0.090596035\n",
      "0.07368853\n",
      "0.07681859\n",
      "0.0786333\n",
      "0.07683511\n",
      "0.08153523\n",
      "0.11041234\n",
      "0.08314718\n",
      "0.101241276\n",
      "0.07210764\n",
      "0.08668619\n",
      "0.060221687\n",
      "0.06183543\n",
      "0.0825049\n",
      "0.07041523\n",
      "0.062796764\n",
      "0.05531367\n",
      "0.07266196\n",
      "0.07287477\n",
      "0.07252896\n",
      "0.0681935\n",
      "0.062040817\n",
      "0.08084877\n",
      "0.067019425\n",
      "0.105579704\n",
      "0.099094115\n",
      "0.13057645\n",
      "0.11161001\n",
      "0.074382156\n",
      "0.08025105\n",
      "0.07751208\n",
      "0.080125794\n",
      "0.085563235\n",
      "0.091509365\n",
      "0.07656712\n",
      "0.07011784\n",
      "0.075249314\n",
      "0.0772412\n",
      "saved to models/pretrained_lstm.ckpt-6\n",
      "0.08323792\n",
      "0.070007995\n",
      "0.070580415\n",
      "0.09760276\n",
      "0.108908124\n",
      "0.08678757\n",
      "0.09237776\n",
      "0.07298573\n",
      "0.06629614\n",
      "0.06543812\n",
      "0.063352965\n",
      "0.07260135\n",
      "0.062220007\n",
      "0.0797597\n",
      "0.060498428\n",
      "0.053059746\n",
      "0.07185155\n",
      "0.06656934\n",
      "0.07752424\n",
      "0.10108164\n",
      "0.09062726\n",
      "0.07901271\n",
      "0.087031856\n",
      "0.0592751\n",
      "0.07625471\n",
      "0.054712154\n",
      "0.05761167\n",
      "0.06193633\n",
      "0.074745886\n",
      "0.09864862\n",
      "0.09827959\n",
      "0.09962976\n",
      "0.10005507\n",
      "0.07031192\n",
      "0.07213915\n",
      "0.068461835\n",
      "0.06458126\n",
      "0.050258096\n",
      "0.066828616\n",
      "11.451465003192425\n",
      "epoch:  7\n",
      "0.07499715\n",
      "0.07712141\n",
      "0.055708066\n",
      "0.049592827\n",
      "0.062021118\n",
      "0.070173725\n",
      "0.049383566\n",
      "0.056329686\n",
      "0.065569736\n",
      "0.05035158\n",
      "0.049504142\n",
      "0.071244076\n",
      "0.06864456\n",
      "0.08024434\n",
      "0.069784045\n",
      "0.08805244\n",
      "0.093442075\n",
      "0.064104386\n",
      "0.07068104\n",
      "0.054727845\n",
      "0.06733311\n",
      "0.05426562\n",
      "0.065358825\n",
      "0.057503745\n",
      "0.057562392\n",
      "0.05585498\n",
      "0.06511839\n",
      "0.05180496\n",
      "0.052264065\n",
      "0.056035347\n",
      "0.05771269\n",
      "0.061102565\n",
      "0.083847046\n",
      "0.08133578\n",
      "0.06972247\n",
      "0.06323512\n",
      "0.05351116\n",
      "0.073956795\n",
      "0.05546297\n",
      "0.05126088\n",
      "0.06230164\n",
      "0.050551686\n",
      "0.065694414\n",
      "0.057617385\n",
      "0.07265678\n",
      "0.06497154\n",
      "0.056862436\n",
      "0.057796355\n",
      "0.060300965\n",
      "0.052942157\n",
      "0.08657816\n",
      "saved to models/pretrained_lstm.ckpt-7\n",
      "0.08320121\n",
      "0.08431946\n",
      "0.06284916\n",
      "0.07402133\n",
      "0.06679591\n",
      "0.074524\n",
      "0.06190273\n",
      "0.07918887\n",
      "0.06666494\n",
      "0.07352289\n",
      "0.06802562\n",
      "0.07907809\n",
      "0.08839034\n",
      "0.061451316\n",
      "0.061601646\n",
      "0.07166437\n",
      "0.06985264\n",
      "0.077117145\n",
      "0.09916538\n",
      "0.06713737\n",
      "0.08461426\n",
      "0.07345196\n",
      "0.072999395\n",
      "0.050016973\n",
      "0.055530336\n",
      "0.072899364\n",
      "0.06754607\n",
      "0.052549638\n",
      "0.046774376\n",
      "0.06264826\n",
      "0.06323424\n",
      "0.06631506\n",
      "0.06663133\n",
      "0.06421049\n",
      "0.05965657\n",
      "0.061928805\n",
      "0.09714656\n",
      "0.08237501\n",
      "0.098398015\n",
      "0.09238284\n",
      "0.07172064\n",
      "0.065916084\n",
      "0.060303383\n",
      "0.06031529\n",
      "0.07552231\n",
      "0.07430033\n",
      "0.06152195\n",
      "0.05402303\n",
      "0.068041794\n",
      "0.07345337\n",
      "saved to models/pretrained_lstm.ckpt-7\n",
      "0.07429343\n",
      "0.07200542\n",
      "0.07228838\n",
      "0.09259319\n",
      "0.10328114\n",
      "0.079895094\n",
      "0.09177144\n",
      "0.06685971\n",
      "0.061060637\n",
      "0.06355698\n",
      "0.06755805\n",
      "0.069704026\n",
      "0.05544645\n",
      "0.06955963\n",
      "0.05781529\n",
      "0.054930877\n",
      "0.06987808\n",
      "0.065801494\n",
      "0.076276705\n",
      "0.10041699\n",
      "0.09093831\n",
      "0.06985111\n",
      "0.07984642\n",
      "0.05402904\n",
      "0.070105255\n",
      "0.051987845\n",
      "0.05510892\n",
      "0.059713166\n",
      "0.06665508\n",
      "0.09795111\n",
      "0.097192496\n",
      "0.10489252\n",
      "0.107532255\n",
      "0.07117684\n",
      "0.07120488\n",
      "0.061453268\n",
      "0.0632244\n",
      "0.055668678\n",
      "0.06814882\n",
      "9.632775790989399\n",
      "epoch:  8\n",
      "0.07483076\n",
      "0.082314834\n",
      "0.05229896\n",
      "0.05222614\n",
      "0.06794842\n",
      "0.06794153\n",
      "0.05106088\n",
      "0.054318037\n",
      "0.07312785\n",
      "0.0542411\n",
      "0.0474163\n",
      "0.07291855\n",
      "0.073339276\n",
      "0.08341311\n",
      "0.06924596\n",
      "0.085253954\n",
      "0.099696696\n",
      "0.06790212\n",
      "0.06765805\n",
      "0.052799843\n",
      "0.06552737\n",
      "0.057032626\n",
      "0.06922632\n",
      "0.058064498\n",
      "0.05626837\n",
      "0.056556877\n",
      "0.06927697\n",
      "0.056495942\n",
      "0.055015333\n",
      "0.05764779\n",
      "0.06497981\n",
      "0.06645931\n",
      "0.09701755\n",
      "0.09394844\n",
      "0.07987962\n",
      "0.06679586\n",
      "0.056653265\n",
      "0.08038077\n",
      "0.056707136\n",
      "0.053042363\n",
      "0.059161637\n",
      "0.04967827\n",
      "0.063355364\n",
      "0.057289477\n",
      "0.06909631\n",
      "0.06896094\n",
      "0.056309048\n",
      "0.058250044\n",
      "0.06220282\n",
      "0.05360615\n",
      "0.087276325\n",
      "saved to models/pretrained_lstm.ckpt-8\n",
      "0.08340836\n",
      "0.08537125\n",
      "0.06490872\n",
      "0.07777296\n",
      "0.06688581\n",
      "0.077994734\n",
      "0.058908004\n",
      "0.082135424\n",
      "0.06936845\n",
      "0.064838976\n",
      "0.07143999\n",
      "0.07581221\n",
      "0.080924414\n",
      "0.059919957\n",
      "0.063887976\n",
      "0.072965436\n",
      "0.06259095\n",
      "0.07424886\n",
      "0.10095012\n",
      "0.06594849\n",
      "0.088746466\n",
      "0.07357979\n",
      "0.07452662\n",
      "0.051779162\n",
      "0.05615928\n",
      "0.067334086\n",
      "0.0710921\n",
      "0.05291775\n",
      "0.04903153\n",
      "0.06308966\n",
      "0.061907377\n",
      "0.064652696\n",
      "0.06482985\n",
      "0.05608306\n",
      "0.053214498\n",
      "0.05374986\n",
      "0.08416683\n",
      "0.08191432\n",
      "0.092815526\n",
      "0.07711643\n",
      "0.058792487\n",
      "0.05932131\n",
      "0.05647804\n",
      "0.05649535\n",
      "0.06255438\n",
      "0.071961366\n",
      "0.054398157\n",
      "0.04982449\n",
      "0.062338997\n",
      "0.067038424\n",
      "saved to models/pretrained_lstm.ckpt-8\n",
      "0.06482731\n",
      "0.06213039\n",
      "0.064034276\n",
      "0.08364879\n",
      "0.09010707\n",
      "0.07229952\n",
      "0.08263208\n",
      "0.06055708\n",
      "0.058383647\n",
      "0.06171002\n",
      "0.057907723\n",
      "0.059511136\n",
      "0.05219715\n",
      "0.06326303\n",
      "0.054789238\n",
      "0.051999748\n",
      "0.065859236\n",
      "0.06557941\n",
      "0.07790996\n",
      "0.093245134\n",
      "0.08546129\n",
      "0.06948901\n",
      "0.08328543\n",
      "0.044800326\n",
      "0.06151864\n",
      "0.04977202\n",
      "0.05062144\n",
      "0.055757985\n",
      "0.074081466\n",
      "0.0907627\n",
      "0.08863705\n",
      "0.10620613\n",
      "0.1048745\n",
      "0.06812561\n",
      "0.07280827\n",
      "0.06447769\n",
      "0.06438234\n",
      "0.058823597\n",
      "0.076348975\n",
      "9.463132362812757\n",
      "epoch:  9\n",
      "0.077883124\n",
      "0.07235329\n",
      "0.06533796\n",
      "0.058950182\n",
      "0.0664524\n",
      "0.06780226\n",
      "0.05648513\n",
      "0.06771565\n",
      "0.07128913\n",
      "0.049910355\n",
      "0.04624845\n",
      "0.06945221\n",
      "0.06866382\n",
      "0.08401349\n",
      "0.068869\n",
      "0.099345386\n",
      "0.10167629\n",
      "0.069804154\n",
      "0.06538059\n",
      "0.054366905\n",
      "0.07772008\n",
      "0.05958403\n",
      "0.07989186\n",
      "0.06332363\n",
      "0.059741613\n",
      "0.062575564\n",
      "0.07516396\n",
      "0.058408618\n",
      "0.057973906\n",
      "0.058986664\n",
      "0.06351771\n",
      "0.06501837\n",
      "0.09730943\n",
      "0.09827928\n",
      "0.077691115\n",
      "0.06894757\n",
      "0.0610305\n",
      "0.071570165\n",
      "0.05650597\n",
      "0.056320015\n",
      "0.06671232\n",
      "0.056524802\n",
      "0.0657099\n",
      "0.06009713\n",
      "0.08121991\n",
      "0.07860452\n",
      "0.05395205\n",
      "0.05809757\n",
      "0.057646822\n",
      "0.051766872\n",
      "0.082282744\n",
      "saved to models/pretrained_lstm.ckpt-9\n",
      "0.07879148\n",
      "0.07999937\n",
      "0.06292714\n",
      "0.0758685\n",
      "0.06760173\n",
      "0.076590836\n",
      "0.06023888\n",
      "0.07559693\n",
      "0.06477299\n",
      "0.06500232\n",
      "0.0716283\n",
      "0.07129242\n",
      "0.080643766\n",
      "0.06053\n",
      "0.056415748\n",
      "0.07378517\n",
      "0.067228034\n",
      "0.07539484\n",
      "0.09960247\n",
      "0.062183198\n",
      "0.07941332\n",
      "0.069787286\n",
      "0.07084264\n",
      "0.05035675\n",
      "0.054421775\n",
      "0.06547287\n",
      "0.06494746\n",
      "0.052837007\n",
      "0.04845253\n",
      "0.06097636\n",
      "0.06075747\n",
      "0.06335755\n",
      "0.06439475\n",
      "0.055442333\n",
      "0.053296044\n",
      "0.056220718\n",
      "0.08240475\n",
      "0.080135465\n",
      "0.08300704\n",
      "0.07884139\n",
      "0.061700437\n",
      "0.056593407\n",
      "0.054216366\n",
      "0.056426365\n",
      "0.059280593\n",
      "0.07200605\n",
      "0.05450327\n",
      "0.046908583\n",
      "0.05541088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.058705475\n",
      "saved to models/pretrained_lstm.ckpt-9\n",
      "0.064014904\n",
      "0.060785238\n",
      "0.06360026\n",
      "0.071961276\n",
      "0.08934366\n",
      "0.07165074\n",
      "0.07456429\n",
      "0.06012278\n",
      "0.04915014\n",
      "0.05331335\n",
      "0.055963743\n",
      "0.058087915\n",
      "0.048998963\n",
      "0.06406159\n",
      "0.059944227\n",
      "0.053153172\n",
      "0.0661457\n",
      "0.061593346\n",
      "0.07028587\n",
      "0.08505402\n",
      "0.08127849\n",
      "0.06755011\n",
      "0.07931491\n",
      "0.04506794\n",
      "0.06662876\n",
      "0.041452497\n",
      "0.046530236\n",
      "0.0501255\n",
      "0.059536323\n",
      "0.090693876\n",
      "0.08528681\n",
      "0.08240134\n",
      "0.0864729\n",
      "0.055147264\n",
      "0.06557536\n",
      "0.053139284\n",
      "0.056794807\n",
      "0.044111878\n",
      "0.06024473\n",
      "9.26053374633193\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "init_g = tf.global_variables_initializer()\n",
    "init_l = tf.local_variables_initializer()\n",
    "sess.run(init_g)\n",
    "sess.run(init_l)\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(\"epoch:  \"+str(i))\n",
    "    #Next Batch of reviews\n",
    "    losses = 0\n",
    "    for j in range(len(X_train)//batchSize):\n",
    "        nextBatch, nextBatchLabels, nextChars = getTrainBatch(j);\n",
    "        #print(j/2)\n",
    "        ll, _,pred,lab = sess.run([loss, optimizer,prediction,labels], {input_data: nextBatch, labels: nextBatchLabels, char_input_data: nextChars})\n",
    "        print(ll)\n",
    "        losses += ll\n",
    "\n",
    "    #Write summary to Tensorboard\n",
    "        if (j % 5 == 0):\n",
    "            summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels, char_input_data: nextChars})\n",
    "            writer.add_summary(summary, j)\n",
    "\n",
    "        #Save the network every 10,000 training iterations\n",
    "        if (j % 50 == 0 and j != 0):\n",
    "            save_path = saver.save(sess, \"models/pretrained_lstm.ckpt\", global_step=i)\n",
    "            print(\"saved to %s\" % save_path)\n",
    "    print(losses)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(100, 20, 2)\n",
      "(3558.0, 3558.0) (44876.0, 44876.0) (661.0, 661.0) (905.0, 905.0) (0.8452765, 0.8433278) (0.7961233, 0.7972216)\n"
     ]
    }
   ],
   "source": [
    "test_batches = 25\n",
    "fin_pred = np.zeros([test_batches*100, 20, 2])\n",
    "jj = 0\n",
    "for j in range(test_batches):\n",
    "    jj = j * 100\n",
    "    nextBatch, nextBatchLabels, nextChars = getTestBatch(j);\n",
    "    pred, acc, tp, tn, fp, fn, p, r = sess.run([prediction, accuracy, true_positives, true_negatives, false_positives, false_negatives, prec, rec], {input_data: nextBatch, labels: nextBatchLabels, char_input_data: nextChars})\n",
    "    \n",
    "    fin_pred[jj:jj+100] = pred\n",
    "\n",
    "print(tp,tn,fp,fn,p,r)\n",
    "    #    for i in range(10):\n",
    "\n",
    "#        print(pred[i][:6])\n",
    "#        print(nextBatchLabels[i][:6])\n",
    "#        print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_analysis = {'original_text': [], 'pred_original_text': [], 'body': []}\n",
    "#for i in range(len(y_test)):\n",
    "for i in range((test_batches*100)):\n",
    "    body = word_tokenize(str(raw_data[train_len:].iloc[i]['body']))\n",
    "    lab_index_test = np.where(np.argmax(y_test, axis=2)[i]==1)[0]\n",
    "    lab_index_pred = np.where(np.argmax(fin_pred, axis=2)[i]==1)[0]\n",
    "    original_text = []\n",
    "    pred_original_text = []\n",
    "    for j in lab_index_test:\n",
    "        original_text.append(body[j])\n",
    "    for j in lab_index_pred:\n",
    "        pred_original_text.append(body[j])\n",
    "\n",
    "    prediction_analysis['original_text'].append(original_text)\n",
    "    prediction_analysis['pred_original_text'].append(pred_original_text)\n",
    "    prediction_analysis['body'].append(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_analysis_pandas = pd.DataFrame.from_dict(prediction_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tru_pos = 0\n",
    "fals_pos = 0 \n",
    "fals_neg = 0\n",
    "true_pos = []\n",
    "false_pos = []\n",
    "false_neg = []\n",
    "def check_tp(original_text, pred_original_text):\n",
    "    global tru_pos, fals_pos, fals_neg\n",
    "    #print((set(original_text)))\n",
    "    #print((set(pred_original_text)))\n",
    "    og = set(original_text)\n",
    "    pr = set(pred_original_text)\n",
    "    res = og.intersection(pr)\n",
    "    true_pos.append(res)\n",
    "    \n",
    "    false_pos.append(pr - res)\n",
    "    false_neg.append(og - res)\n",
    "    tru_pos += len((set(original_text).intersection(pred_original_text)))\n",
    "    fals_pos += len(pr -res)\n",
    "    fals_neg += len(og - res)\n",
    "    \n",
    "for i in range(2500):\n",
    "    check_tp(prediction_analysis_pandas.iloc[i]['original_text'], prediction_analysis_pandas.iloc[i]['pred_original_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3556, 661, 880, 0.8432534977472137, 0.8016230838593328, 0.8219114757887439)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp = tru_pos/ (tru_pos + fals_pos)\n",
    "rr = tru_pos/ (tru_pos + fals_neg)\n",
    "tru_pos, fals_pos, fals_neg, pp, rr, (2*pp*rr)/(pp+rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_analysis_pandas['false_positives'] = false_pos\n",
    "prediction_analysis_pandas['true_positives'] = true_pos\n",
    "prediction_analysis_pandas['false_negatives'] = false_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_analysis_pandas.to_csv('/home/pratik/Desktop/haptik/chatbot_ner/pratik_ner/models/LSTM/lstm_word_char_embeddings/pos_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
